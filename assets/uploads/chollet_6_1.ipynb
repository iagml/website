{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chollet_6_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3mEy_mOiYu8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Deep Learning with Python\n",
        "\n",
        "## Capítulo 6: Deep learning for text and sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecL2YtVsi6UA",
        "colab_type": "text"
      },
      "source": [
        "Tipos de dados a serem trabalhados:\n",
        "\n",
        "*   Texto (sequência de palavras ou caracteres)\n",
        "*   Série temporal\n",
        "*   Sequências de dados em geral\n",
        "\n",
        "----\n",
        "Algoritmos fundamentais:\n",
        "\n",
        "*   Recurrent neural networks\n",
        "*   1D convnets\n",
        "\n",
        "----\n",
        "Aplicações possíveis:\n",
        "\n",
        "*   Classificação de documentos e timeseries, para identificação de tema ou autor\n",
        "*   Comparações entre timeseries, para identificação de similaridade entre 2 documentos\n",
        "*   Aprendizado sequence-to-sequence, para traduções\n",
        "*   Análise de sentimentos\n",
        "*   Previsão de tempo\n",
        "\n",
        "---\n",
        "\n",
        "Aplicações que faremos:\n",
        "*   Análise de sentimentos\n",
        "*   Previsão do tempo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afIdF-fouY_q",
        "colab_type": "text"
      },
      "source": [
        "#### Vetorizando texto:\n",
        "\n",
        "* Segmentar o texto em palavras e transformá-las em vetores\n",
        "* Segmentar o texto em caracteres e transformá-los em vetores\n",
        "* Extrair n-gramas das palavras e transformá-los em vetores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuOd4iMwxwvJ",
        "colab_type": "text"
      },
      "source": [
        "#### O que são n-grams?\n",
        "\n",
        "![N-grama](https://i.stack.imgur.com/8ARA1.png)\n",
        "\n",
        "-----\n",
        "![alt text](https://www.simplicity.be/articles/throwing-dices-recognizing-west-flemish-and-other-languages/img/ngrams.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_1nB_pm4C__",
        "colab_type": "text"
      },
      "source": [
        "#### Tokens e vetorização\n",
        "\n",
        "* O processo de quebra de um texto em partes menores se chama *tokenization* e as partes em que são quebradas se chama *token*.\n",
        "\n",
        "\n",
        "* Processo de *text-vectorization* consiste de aplicar a tokenização ao texto e associar vetores aos tokens.\n",
        "\n",
        "* Usamos os vetores associados aos tokens para os modelos de deep learning.\n",
        "\n",
        "* Os dois principais métodos de vetorização de palavras são **one-hot encoding** e **embedding**.\n",
        "\n",
        "![alt text](https://freecontent.manning.com/wp-content/uploads/Chollet_DLfT_01.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NQdaODl7gQ4",
        "colab_type": "text"
      },
      "source": [
        "## One-hot encoding\n",
        "\n",
        "* Método mais comum e básico de vetorizar um token\n",
        "* Usado no capítulo 3 para os cases do IMDB e Reuters\n",
        "\n",
        "![alt text](https://miro.medium.com/max/2736/0*T5jaa2othYfXZX9W.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSz9Ytl2xKd0",
        "colab_type": "text"
      },
      "source": [
        "## One-hot encoding com palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKSfzsyMiRZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "token_index = {}\n",
        "for sample in samples:\n",
        "  for word in sample.split():\n",
        "    if word not in token_index:\n",
        "      token_index[word] = len(token_index) + 1\n",
        "      \n",
        "max_length = 10\n",
        "\n",
        "results = np.zeros(shape=(len(samples),\n",
        "                         max_length,\n",
        "                         max(token_index.values()) + 1))\n",
        "\n",
        "for i, sample in enumerate(samples):\n",
        "  for j, word in list(enumerate(sample.split())) [:max_length]:\n",
        "    index = token_index.get(word)\n",
        "    results[i,j,index] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkVDqA-gmkLt",
        "colab_type": "code",
        "outputId": "4a0c479a-953b-4c7f-8e4d-2e5d45ead7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWlCjNR0xSST",
        "colab_type": "text"
      },
      "source": [
        "## One-hot encoding com caracteres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAl7Hk_zxDD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "characters = string.printable\n",
        "token_index = dict(zip(range(1,len(characters)+1), characters))\n",
        "\n",
        "max_length = 50\n",
        "\n",
        "results = np.zeros((len(samples), max_length, max(token_index.keys())+1))\n",
        "for i, sample in enumerate(samples):\n",
        "  for j, character in enumerate(sample):\n",
        "    index = token_index.get(character)\n",
        "    results[i,j, index] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98yqxNx7xeiV",
        "colab_type": "code",
        "outputId": "4a1d3f35-f774-471f-edaf-3b2f43b30053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGZK-_7bynkw",
        "colab_type": "text"
      },
      "source": [
        "## One-hot encoding com o Keras\n",
        "\n",
        "Ainda que seja possível fazer o one-hot encoding 'na mão', é recomendado que seja feito com o Keras, pois ele saberá lidar com várias issues importantes quando lidamos com texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc5KV470yPus",
        "colab_type": "code",
        "outputId": "1a76d0f7-7838-4563-e252-ed417fe2769f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(samples)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(samples)\n",
        "\n",
        "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %d unique tokens.' %len(word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSje7s5pzNcN",
        "colab_type": "code",
        "outputId": "b091fe3e-1d49-40e2-81c8-d612acf8bcbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ate': 7,\n",
              " 'cat': 2,\n",
              " 'dog': 6,\n",
              " 'homework': 9,\n",
              " 'mat': 5,\n",
              " 'my': 8,\n",
              " 'on': 4,\n",
              " 'sat': 3,\n",
              " 'the': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HW_6SiWztFp",
        "colab_type": "code",
        "outputId": "afcc152b-5da5-4590-cdf0-98fb31ae8776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "one_hot_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD8iA4wiz2Ch",
        "colab_type": "code",
        "outputId": "cbd0e803-30b1-4936-a53a-7b5717b2fe7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HqkCqPT0z8b",
        "colab_type": "text"
      },
      "source": [
        "## One-hot encoding para grandes vocabulários\n",
        "Quando a quantidade de tokens for suficientemente grande, vale usar o **one-hot encoding hashing trick**\n",
        "\n",
        "> Uma função **hash** é um algoritmo que mapeia dados de comprimento variável para dados de comprimento fixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwuPUMgl0Z9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "dimensionality = 1000\n",
        "max_length = 10\n",
        "\n",
        "results = np.zeros((len(samples), max_length, dimensionality))\n",
        "for i, sample in enumerate(samples):\n",
        "  for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "    index = abs(hash(word)) %dimensionality\n",
        "    results[i, j, index] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5TY8PIk2WN1",
        "colab_type": "code",
        "outputId": "4b38a3ec-c9b0-4a74-8b7f-e5d04ea9db99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8kW-jT4KRrY",
        "colab_type": "text"
      },
      "source": [
        "## Embeddings\n",
        "\n",
        "* Embeddings é uma outra maneira de vetorizar palavras através de vetores densos (oposto ao vetores esparsos do one-hot encoding). A vetorização por embedding possibilita compactar informações em vetores com menores dimensões.\n",
        "\n",
        "![alt text](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOAAAADhCAMAAADmr0l2AAAApVBMVEX///8AAACIiIjn5+f8/Pzu7u6dnZ3MzMzT09MYGBhUVFRKSkq/v781NTUFBQXj4+NdXV3d3d09PT2Xl5fx8fG6t7eNjY1ERESmpqaBgYFjY2OgoKBubm7X19cnJyfe3t6wra14dHQuLi43Li7FxcU5OTlQUFCGgoJLRERfVlZuZWWup6efl5dISUk+NzdpY2MnHBweHh4xKCgdDQ0gICBbTEyXjY2AQvbbAAALxUlEQVR4nO2dC3ubuBKGx0hcgnG4SYAwGMFi0m6bdrsn5/z/n3ZGXFw7cZ2EJms7q+9xE0YQpJfbzEgyBdDS0rpUVf6giu4ZPhp0WvbhkXFVootJJlo7gwDYOwNXOPvGVekFgDegAS9YGlADXrg0oAa8cJ0CvO3VAxI66iNGMj3gtD359a4uUxpQA164NKAGvHC9FtA8X1Pn6YWOvuyCQd25G/xa/atDNQ14DdKAGvDCpQGvHZBZclCmgpVDwD1H70zG9QGyaUl1RnzEMzgFl1QDasCLlAbUgBeuj+8m4mzQ+oM6+g8fqmlADXjh0oAa8MKlATXghUsDasALlwbUgBcuDagBL1waUANeuDSgBrxwacAPBUj96dsD1cccm6C7aaHhBz2DGlADXpw0oAa8cB0C7mYkfFBA+JFGvRo9CeFqpAE14IVLA2rAC9fZAE1nlK2M9TQlEI1y/B6AbNHw21HOtQH63iipmPZ3v77Z9Lqp0WjjUdnMei4DMNzffbZZ9WoGQGuQBvyFNKAGnCkN+G8BtNa9LDmznrO9Ga/6MuorGuEfnwb9jcaXb8Pytzs0vDuj193XNwcMJR+UwXtk9KUYWm6o80TMQaxEgxtJL0OFNTLtei3rNwc8eH3F25/BA0CfjFJxG5/WWGjIpduru5tZjwbUgDOlATXgy6QB3w3wbvB2Se8HR5kqb+d3+35w+bnXOwCG/F0d/cEhC2+aQf9Bw5pWFGhkk5G/OeA7h2qHgNvloD/OAfg+wbYG1IAaUANqwLcDfBh6KVZ/PQZcT0YwG/B2dOEnX/33Dhl9fTfoTzT8KaNXkYwcXzPo/k9tFo6yZwOe6QwexqJTqQoLpTu+RzFBI5yiuHJmPRcGqBYmQFcDvkQaUAPOlAa8fsC9jP7QTXRDL4VroFGNHtIMZ9ZzPkf/aeiL+PxfNPwv47wDNQLhfR31BQ3+vRiUzAY81xnc3g+KFOA0SKZ6Xpxp3EnNspA/hr6MTXF9gGN8fQCorkp7AvQU4P5YmgbUgBpQA2rAHWAzzH+PvinAcarBWnk7xxum3w1uYpy49uPq3EQ4zi+UMRrV9z8HfUaDjyFOohx9O81DlDPrOd80kv3xlnCcatCp03kwulSZ42ZXF4sejJiF6Rh+PgHcBdvXN19UA2pADagB/wnA0U3sA+7PVbteNxHuJ/HV59HRq/ReBt8HqbDGnjaTM+s51WXxroAHezwI1Y6PLs0ffDnTGTwE3A+2P+LwmQbUgBpQA2rAVwP+NUjNv/O/jt8xUMPy67/+6PW36oaRkzG/y+JcYxP3Y3T2CR4NvkyhWqJCNW8yrJn1nK/TKT0GqBYOgm1vMuKZ9WhADThTGlADvkznAzzqJj4QoDN+S/BTPzYxvZGvBxxn6fVfGeT1njEP8EyOfvoGaCvh0YsCslXaK1ID9h/xRQEyGsbV0h5wDFKtLzPruXjAWAOelgbUgDOlAf85wFt4lxcF8D3AQz/YbHuNr3r4XT+4GSc7bBTgw2QgoDNNg7iHvTkR2zfiAzoNG6kknlb+oAoNNi775LGhpaWlpaWl9a8W+7HhBwXOLvQi9Ohf0D6Ee6RfbHtaEYDY25d9GPSRPXNhY7wWANy+PnoxSthUbYyQ63hoZKDma8qEknQc3vAAzJImEuwMw0TT6vpGlT7YjKqAkBsluVfbWhYQq02AJWsKvny27g5YDqEoQXqWDY6VDsXSYCTzElpn2BBb+ECtwgZuFaBeVYkVUAixwSzJcIGfrgIgZ7CiC2fJEs8WYJoMtnbs8djpoPCGuUTCXHt2FwqPBTzFw5H3gCSHBoJqzT1hplBwBwzOBU2EERZ2y14CKKQoYGVumX8bdr7rRwOf5ed2ssl4LWVCcraCyDFsmZR4MCIKucETFhGsu8RawmdrKUxspwuWHwRuDHWe4XG1JV45ESTj9eAlC4OlQAQICpUBxnBZpbh4kwetoTZT22L7tsBbzHvc/EVXbLZyiyqGrMUGQGarnwrbDYy2zUte4OH3oiCAJXCnQDRQH8Okdctx26p7US0yCTtIIa4Mmw7f+r1HQJnhWYm9sH9POll4C1ixtYS8pLSBaJhD5eG9uDSJzwXjYPGKirYswJIMPLrmQJ69eKBtYgNW4JosMsEz2HDTZVJNQg8cWZDMqgq8Q25ozWNe3gPrfBCE1X4OC6wl9qDynq0lLhhk0Jog6qE3OQPf6UupMIZDFIMFZhFDawgHvGKaQ4V3CCsEg3WOZ03g2cV/lTAkOOp7U9X62apNr7LBzj2wEtxNLDJnbFFZhZI4To33Nc85lDk+FkQcsyQRZssoBykasLFFUM5NCi9ceTJ3gP5KRHWy+1Qkbdpz1S3SuTMmXqGamJLgLQzUNoGUpATq4YVQzn2hwmvkAsfwwKOsCvE5E6oD7R0Jl35Pzo0DfCFvgcsVOFtjA6lXY1RhzZ2t8QoFlHZ06S3ZQnQlPjMl1h3NCf6OiG2a0ZWwIGMCkqrMbxjUtILE9SBw3fd7Xpmb8a5AwKBdBQsMMlrJUsHIbbCZO2P5VwqABsyAJd2ASxFQTcFxGbrDN79WngovUcu2gGHMgoBAXOrCG53An/JWW8IWqYR1Wkh+n7Z469fA0vT5WOG3pWqCOsVYEOzWT1MHsih4c0IUhpsfW9R/fhutS5XsP8ZgJD9DIWnvSh/pcak/99UEmBj8el2JQTs/+laHJ6XJyQsw6j+j0zOcXZW2sSuFw0ebNRWMpXR1av+nVJgHO9/fKVBsVes/XqP+tdWj3cQnn4dLQjAxbPBwbhuPb9zhdJTNfaxK6SJKDZoGWbtY3kKZdi2kG0ytug3tVlECIqhhTFhnAtJVYDhriq4pdSVrotUQQqXBBuLbEoLm/gHqIoVF94B1F3VfSpqUe7fLG7C7hgE/BsjyfNiTKwQ2cAmYgTrqv+ZIwcoF2qahSpmIzWJdZw+4Og7bXGVuuG0DZWxj3AEm374ecFe3ApQcOiaC1sC8sMFskjllnjPO+2zfAZdkBdtkaRVXrIY+OMFSQbAJDUYnwFW3zdEzaJrDxZCqXH4AxIzeVj1CJsNSkoyApLA8QrDcKoHFyQhYJS22DDZ+qjqRXqmp7oJhzq5QuqLhSYu1hHjnUdME6amGrUtw/awwA5OAgRk9Xp54O2QlBtDY3A5iX3hG2XeX/For1aPiLlyIg4ZnLYw9QGmwoMEiYLVBArapayyPS94FXr+tFTQml1jW1AsHkuD5boqjKlxXwAYvu87ZlqSpBY02g0tmN8XCWT9ETldZAQT1lgqfFfRBFGA9RDZp3Ez1HvlW3tQQrl701XqTrPfayQ7WTRalj1fTpxu/VuzJwm7Hu7Y9WWD7v19Wv1PMncandVaV/Wen6olvbccLgLZvHgZXJ/ZIpoy7Pertwxe/2Wnbf37+4ZNHYj09hNM3T6DyE3s0N8NvKz7at1AOvok+/3hL1XM/x0zFrVMOeTfkuaZKl+qthPIek9M8RWdzf2zw5ffURzIizXDnAjK3KLw6zYF0SxNE1/SbYIAhWSRWPklTJt16NQQ1+bKABHO86Md927f+ieg6G06yG0UBmGGuHEYSq970NpN4bGlmx8oPgNdmcdmgszTeCpBmmb8DtIvwFihZUiiogAXUpttK0caTdxVIVBl+G1BSxL6b9feTYWOizkgETAXGZnmk94F63hBYqzPIoqzoA5LaxJ+O1yrfD+iCa5aCZ8cxb4lxMOT1e4BT3ejoE08oV5+hO1Y9bB3G+ynnITrkCRAfAaHV30cuBh0DYMEgh0ZiOIKAJFqf8oO454i48QaymzXwPLntnynSzWK6wThsKVNRudyAW76QbwS4UxHHgq68ArbewnGauMJLxvAtI+N+JBd9TF1tE5sKl4MlBE9IsO4BZZHcsEYuCGykrIJ4c+JpVamP45fgqJ5CJxwGXqBs1RgCqH68EnzMa5hnPo7if1vEcQjWwoC1JiGlY2JTCAUbG1LZpL9gTNyEOiVi2Q6u88cgzw5DShyf4V9TbL3zHv0cWlpaWlpaWlpaWq/S/wG8FWgmpsSfVQAAAABJRU5ErkJggg==)\n",
        "\n",
        "* Como fazer o embedding?\n",
        "  * Aprender o embedding durante a predição, em que se inicia com vetores aleatórios e vai aprendendo com as iterações, similar aos pesos da rede neural.\n",
        "  * Carregar embedding prévios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wt1_0A1y3TJ",
        "colab_type": "text"
      },
      "source": [
        "* Nos embeddings, espera-se que a distribuição espacial dos vetores tenham relação com a semântica das palavras. Palavras que possuam similaridades são esperadas como estando próximas entre si e distantes de outras categoricas e tipos.\n",
        "\n",
        "![alt text](https://freecontent.manning.com/wp-content/uploads/Chollet_DLfT_03.png)\n",
        "\n",
        "![alt text](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/06062705/Word-Vectors.png)\n",
        "\n",
        "> Material interessante sobre word2vec: [The Illustrated Word2vec](http://jalammar.github.io/illustrated-word2vec/)\n",
        "\n",
        "> Embeddings com Tensorflow: [Embedding Projector\n",
        "](http://projector.tensorflow.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTScqlOTMGkm",
        "colab_type": "text"
      },
      "source": [
        "* Importante lembrar que o melhor modelo de embedding irá depender das especificidades de cada problema.\n",
        "\n",
        "> O Keras possui uma camada própria para isso, que facilita a vida: *Embedding Layer*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeDg1U_j2fGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(1000,4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwBILJmIOqzC",
        "colab_type": "text"
      },
      "source": [
        "A camada Embedding é uma espécie de dicionário que mapeia as índices inteiros em vetores densos.\n",
        "\n",
        "**Word index -> Embedding layer -> Corresponding word vector**\n",
        "\n",
        "> Precisamos de um vetor 2D de shape (samples, sequence_lenght) como entrada.\n",
        "\n",
        "> A camada Embedding aceita sequências de diversos tamanhos, mas todos as sequências de um mesmo batch precisa ser do mesmo tamanho:\n",
        "* sequências pequenas são preenchidas por zeros e sequências grandes são truncadas.\n",
        "\n",
        "> A camada retorna uma tensor 3D (samples, sequence_length, embedding_dimensionality), que pode ser processada por uma camada RNN ou uma camada convolutiva 1D."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjo05XVuRY1n",
        "colab_type": "text"
      },
      "source": [
        "## IMDB Case\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW_La6z4Lj0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "\n",
        "max_features = 10000\n",
        "maxlen = 20\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAOQjGzeObSV",
        "colab_type": "code",
        "outputId": "b3e30a05-abde-4d04-e4ba-06e7589ff469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "x_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  65,   16,   38, ...,   19,  178,   32],\n",
              "       [  23,    4, 1690, ...,   16,  145,   95],\n",
              "       [1352,   13,  191, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [  11, 1818, 7561, ...,    4, 3586,    2],\n",
              "       [  92,  401,  728, ...,   12,    9,   23],\n",
              "       [ 764,   40,    4, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCPtVmyGSOSu",
        "colab_type": "code",
        "outputId": "10c1f2ea-ea87-44bd-e339-c24df383af11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04LdBQzHSQ4O",
        "colab_type": "code",
        "outputId": "bfc119ca-28a7-4ed3-ca5d-94f57f5d97ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 8, input_length=maxlen))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                   epochs=10,\n",
        "                   batch_size=32,\n",
        "                   validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 20, 8)             80000     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 161       \n",
            "=================================================================\n",
            "Total params: 80,161\n",
            "Trainable params: 80,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 2s 79us/step - loss: 0.6582 - acc: 0.6409 - val_loss: 0.5989 - val_acc: 0.7000\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 1s 70us/step - loss: 0.5261 - acc: 0.7546 - val_loss: 0.5183 - val_acc: 0.7324\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 1s 72us/step - loss: 0.4571 - acc: 0.7893 - val_loss: 0.4971 - val_acc: 0.7480\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 1s 71us/step - loss: 0.4226 - acc: 0.8079 - val_loss: 0.4943 - val_acc: 0.7530\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 1s 70us/step - loss: 0.3994 - acc: 0.8203 - val_loss: 0.4929 - val_acc: 0.7542\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 1s 71us/step - loss: 0.3798 - acc: 0.8315 - val_loss: 0.4945 - val_acc: 0.7552\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 1s 70us/step - loss: 0.3619 - acc: 0.8406 - val_loss: 0.4992 - val_acc: 0.7556\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 1s 72us/step - loss: 0.3452 - acc: 0.8516 - val_loss: 0.5027 - val_acc: 0.7600\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 1s 71us/step - loss: 0.3290 - acc: 0.8614 - val_loss: 0.5077 - val_acc: 0.7564\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 1s 71us/step - loss: 0.3130 - acc: 0.8687 - val_loss: 0.5150 - val_acc: 0.7552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP9mCVnLTLHI",
        "colab_type": "text"
      },
      "source": [
        "> Obtivemos uma acurácia de **~75%**\n",
        "\n",
        "> Esse modelo não leva em conta as relações entre as palavras e a estrutura da sequência."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fadvq1cULtw",
        "colab_type": "text"
      },
      "source": [
        "# Próximo encontro\n",
        "\n",
        "* Tratamento das sequências como um todo e análises de resultados\n",
        "* RNN para textos\n",
        "\n",
        "> ![alt text](https://media2.giphy.com/media/J4zA6LplubvC5weDyo/giphy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHlRdljZ4WJj",
        "colab_type": "text"
      },
      "source": [
        "## Continuação 6.1\n",
        "> 08/11\n",
        "\n",
        "### EMBEDDINGS PRÉ-TREINADOS\n",
        "\n",
        "- Nem sempre teremos dados de texto o suficiente para criar um embedding específico.\n",
        "- Como no estudo de imagens, vale usar de embeddings criados anteriormente e que seja capaz de captar características genéricas da semântica de um idioma.\n",
        "- Em geral se utiliza estudos anteriores, muitos deles produzidos pela galera de linguística (vale muito procurar trabalhos do [Grupo de Linguística Computacional](https://glicusp.wordpress.com/) da FFLCH, que tem encontros abertos a todos!)\n",
        "- Modelos de embedding avançaram bastante após a criação do algoritmo de Word2Vec, que é capaz de captar as propriedades semânticas de um texto.\n",
        "- Além do Word2Vec, no Keras é possível utilizar o GloVe (Global Vectors for Word Representation), que utilizaremos também\n",
        "\n",
        "----------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gupQRBn1j6Pk",
        "colab_type": "text"
      },
      "source": [
        "### From raw text to word embeddings\n",
        "\n",
        "## Transformando cada review em uma lista de strings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxkz_s3LK-za",
        "colab_type": "code",
        "outputId": "f014a2bf-0909-4085-cde6-8c704fa0d2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YUn2wjxTCsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "imdb_dir = r'/content/drive/My Drive/Deep_Learning/aclImdb'\n",
        "train_dir = os.path.join(imdb_dir, 'train')\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quOgY8hpamOj",
        "colab_type": "code",
        "outputId": "b1995f1d-4c9b-4a48-98b6-6e2892cac97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "for label_type in ['neg', 'pos']:\n",
        "  dir_name = os.path.join(train_dir, label_type)\n",
        "  for fname in os.listdir(dir_name):\n",
        "    if fname[-4:] == '.txt':\n",
        "      f = open(os.path.join(dir_name, fname))\n",
        "      texts.append(f.read())\n",
        "      f.close()\n",
        "      if label_type == 'neg':\n",
        "        labels.append(0)\n",
        "      else:\n",
        "        labels.append(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-42c7d6a25601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mdir_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Deep_Learning/aclImdb/train/neg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KTuvYnMkANt",
        "colab_type": "text"
      },
      "source": [
        "## Vetorizando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyY4Ha75kDkr",
        "colab_type": "code",
        "outputId": "a12e895d-0a65-493c-8887-0d5c52dcb2ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "maxlen = 100\n",
        "training_samples = 200\n",
        "validation_samples = 10000\n",
        "max_words = 10000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0zuI7tFN3YY",
        "colab_type": "code",
        "outputId": "55d0a819-d1b8-494d-8be2-476660ccb1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 0 unique tokens.\n",
            "Shape of data tensor: (0, 100)\n",
            "Shape of label tensor: (0,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH0Y5PkUaXUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-M-aD5nZifH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Deep_Learning/aclImdb/teste.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K3702utaVcV",
        "colab_type": "code",
        "outputId": "48ae20c5-47fc-49ef-fd6e-6cc257d7728a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   a   b   c\n",
              "0  1   2   3\n",
              "1  4   5   6\n",
              "2  1   2   3\n",
              "3  2   3   5\n",
              "4  7  11  13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCBnbfC9acD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}